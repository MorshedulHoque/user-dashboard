-- phpMyAdmin SQL Dump
-- version 5.2.1
-- https://www.phpmyadmin.net/
--
-- Host: 127.0.0.1
-- Generation Time: Oct 05, 2024 at 03:55 PM
-- Server version: 10.4.32-MariaDB
-- PHP Version: 8.2.12

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `linkedin_commenter_draft`
--

-- --------------------------------------------------------

--
-- Table structure for table `comments_history`
--

CREATE TABLE `comments_history` (
  `id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `post_text` text DEFAULT NULL,
  `generated_comment` text DEFAULT NULL,
  `emotion` varchar(255) DEFAULT NULL,
  `created_at` datetime DEFAULT current_timestamp()
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `comments_history`
--

INSERT INTO `comments_history` (`id`, `user_id`, `post_text`, `generated_comment`, `emotion`, `created_at`) VALUES
(1, 1, '???? ???????????????? is hiring a Machine Learning Engineer offering up to $477K+ in TC! Here\'s the inside scoop to land this role????\n\n????. ???????????????????? ????????????????????????????????\n↳ ML algorithms: GBM, clustering, neural networks, transformers\n↳ Coding: Proficiency in DSA and PyTorch\n↳ ML System Design: Design scalable systems - spam detection, feed ranking\n↳ Behavioral: stakeholder management, leadership, communication\n\n????. ???????????????? ???????????????????????????????? ???????? ????????????????????\n↳ News Feed\n↳ Ads\n↳ Notification\n↳ AR/VR \n↳ Instagram\n↳ Messenger\n\n????. ???????????????????????????????????? ????????????????????????\n\nA single round consisting of the following:\n\n⏰ ????????????????????????????????: 45-60 minutes\n???? ????????????????????????????????????????????: Senior/Staff ML Engineer or Research Scientist\n???? ???????????????????????????????? ????????????????????: 2-3X data structures & algorithms, ML coding\n\n????. ???????????????????????? ????????????????????\n\nUsually, 4 rounds in total with 45-60 minutes each, conducted by a seasoned MLE or ML tech lead. The rounds are:\n\n???? Coding Interview\n???? ML System Design - Round 1\n???? ML System Design - Round 2\n???? Behavioral\n\nNow go ace your next interview????\n\n???? ???????????????????????????????????? ???????????????? ????????????????????????????: https://lnkd.in/gzgB-dHT\n???? ???????????????? ???????? ???????????????????????????????????? ????????????????????????????????: https://lnkd.in/eiA5Ntdp\n???? ???????????????? ???????????? ???????????????????????????????????? ????????????????????????????????: https://lnkd.in/e6HbN6dy\n???? ???????? ???????????????????????????? ????????????????????????: https://lnkd.in/g82dMJ77\n\n???? Smash ???? and follow Daniel Lee for data & AI\n…more', 'Wow, $477K+ TC?!  I guess Meta\'s really trying to attract top talent.  I\'m just hoping they\'re not looking for someone to debug their \"News Feed\" algorithm... ????  Seriously though, good luck to anyone going for this role!  It sounds like a tough but rewarding challenge.', 'Funny', '2024-09-23 03:51:28'),
(2, 1, 'ML Interview Question: \nWhat is Knowledge Distillation? \n\nKnowledge Distillation is a method used to transfer knowledge from a large, complex model (teacher model) to a smaller, simpler model (student model). The goal is to make the smaller model faster and more efficient, while still maintaining a good level of accuracy. \n\nHere’s how it works:\n\n1.Teacher Model: Train a large model on the dataset. This model can make very accurate predictions but is too big or slow for real-world use.\n\n2. Soft Labels: Instead of using just the correct answers (hard labels), the teacher gives the probabilities for each possible class (soft labels). These contain more information, like how confident the teacher is about each answer.\n\n3.Student Model: The smaller model is trained using the teacher\'s soft labels, learning to imitate the teacher\'s predictions.\n\nWhy is it useful?\nThis technique is great for applications like mobile devices, where speed and memory are limited. By training the smaller student model, you get a model that’s much faster and more efficient but still close in performance to the teacher model.\n\nKnowledge distillation helps bridge the gap between high performance and practical deployment by compressing complex models into faster, lightweight versions.\n\n\nhashtag\n#machinelearning \nhashtag\n#knowledgedistillation \nhashtag\n#AI \nhashtag\n#MLinterview', 'So, basically, we\'re teaching a smaller model how to cheat off the big one? ????  Sounds like a good strategy for getting a good grade, but I\'m not sure how well it\'ll translate to real-world applications!  ????  #knowledgedistillation #MLinterview #AI', 'Funny', '2024-09-23 04:32:45'),
(3, 1, 'I want to take a moment to sincerely express my gratitude for the immense value the CampusX YouTube channel has added to my data science learning journey.\n\nI\'ve been following this channel for the past one and a half years, and I must say, his teaching skills are mind-blowing. The way Nitish blends theory with real-world examples makes the learning process not only effective but also incredibly engaging.\n\nIf you\'re looking to start your journey in data science or want to enhance your skills, I highly recommend checking out CampusX. It\'s a treasure trove of knowledge, all provided for free, making high-quality education accessible to all!\n\nThank you, Nitish Singh and CampusX, for empowering countless learners like me. ????\nCheck out the channel here: https://lnkd.in/gqeUyzqe\n\n\nhashtag\n#DataScience \nhashtag\n#MachineLearning \nhashtag\n#DeepLearning \nhashtag\n#LearningJourney \nhashtag\n#CampusX \nhashtag\n#Education \nhashtag\n#Gratitude \nhashtag\n#MachineLearningJourney \nhashtag\n#GratefulForMentorship \nhashtag\n#DataExploration \nhashtag\n#NLP', 'That\'s fantastic to hear! Nitish\'s teaching style is truly exceptional, and CampusX provides invaluable resources for anyone interested in data science.  It\'s great to see such high-quality education accessible to everyone.  Thank you for sharing your experience!', 'Supportive', '2024-09-23 21:14:11'),
(4, 1, 'If you are still thinking about going to FLOW London, don’t wait any longer.\nJust 3 tickets left…', 'FLOW London is a must-attend event, and it\'s clear there\'s a lot of interest! Only 3 tickets remain, so don\'t miss out on this opportunity to connect with industry leaders and gain valuable insights. Secure your spot today!', 'Informative', '2024-09-23 22:39:00'),
(5, 1, 'Alibaba presents MIMO\n\nControllable Character Video Synthesis with Spatial Decomposed Modeling\n\nCharacter video synthesis aims to produce realistic videos of animatable characters within lifelike scenes. As a fundamental problem in the computer vision and graphics community, 3D works typically require multi-view captures for per-case training, which severely limits their applicability of modeling arbitrary characters in a short time. Recent 2D methods break this limitation via pre-trained diffusion models, but they struggle for pose generality and scene interaction. To this end, we propose MIMO, a novel framework which can not only synthesize character videos with controllable attributes (i.e., character, motion and scene) provided by simple user inputs, but also simultaneously achieve advanced scalability to arbitrary characters, generality to novel 3D motions, and applicability to interactive real-world scenes in a unified framework. The core idea is to encode the 2D video to compact spatial codes, considering the inherent 3D nature of video occurrence. Concretely, we lift the 2D frame pixels into 3D using monocular depth estimators, and decompose the video clip to three spatial components (i.e., main human, underlying scene, and floating occlusion) in hierarchical layers based on the 3D depth. These components are further encoded to canonical identity code, structured motion code and full scene code, which are utilized as control signals of synthesis process. The design of spatial decomposed modeling enables flexible user control, complex motion expression, as well as 3D-aware synthesis for scene interactions. Experimental results demonstrate effectiveness and robustness of the proposed method.\n…more', '', 'Informative', '2024-09-25 12:36:29'),
(6, 1, 'Data Scientist: \n\n\"My model has 0.94 AUC!\"\n\"My AB test returned a P-value of 0.03!\"\n\"The linear model achieved a 0.92 R-squared!\"\n\nClient: \"Great! But how does it help me?\"\n\nDelivering the solution is just half the job of a data scientist. \nThe other half? ???????????????????????? ???????? ????????????????????????????????????????.\n\n• ???????????????????????????????????? what the result means for their business.\n• ???????????????????????????????? why your solution matters.\n\nWhat you think is a great solution may go nowhere if your stakeholder doesn\'t see the value. Help them see it.\n\n⤷ How do you communicate data insights to stakeholders? Drop a tip????\n\n⤷ Want to break into Data/ML role? Use these????\n\n???? ???????????????????????????????????? ???????????????? ????????????????????????????: https://lnkd.in/gzgB-dHT\n???? ???????????????? ???????? ???????????????????????????????????? ????????????????????????????????: https://lnkd.in/eiA5Ntdp\n???? ???????????????? ???????????? ???????????????????????????????????? ????????????????????????????????: https://lnkd.in/e6HbN6dy\n???? ???????? ???????????????????????????? ????????????????????????: https://lnkd.in/g82dMJ77\n…more', 'This post highlights a crucial aspect of data science: translating technical results into actionable insights for stakeholders.  Communicating the \"why\" behind the \"what\" is essential for driving business value.  \n\nA clear and concise story, tailored to the stakeholder\'s needs, can bridge the gap between technical findings and practical application.  \n\nSharing your own communication tips in the comments can be valuable for others in the field!', 'Informative', '2024-09-25 12:36:51'),
(7, 1, 'Alibaba presents MIMO\n\nControllable Character Video Synthesis with Spatial Decomposed Modeling\n\nCharacter video synthesis aims to produce realistic videos of animatable characters within lifelike scenes. As a fundamental problem in the computer vision and graphics community, 3D works typically require multi-view captures for per-case training, which severely limits their applicability of modeling arbitrary characters in a short time. Recent 2D methods break this limitation via pre-trained diffusion models, but they struggle for pose generality and scene interaction. To this end, we propose MIMO, a novel framework which can not only synthesize character videos with controllable attributes (i.e., character, motion and scene) provided by simple user inputs, but also simultaneously achieve advanced scalability to arbitrary characters, generality to novel 3D motions, and applicability to interactive real-world scenes in a unified framework. The core idea is to encode the 2D video to compact spatial codes, considering the inherent 3D nature of video occurrence. Concretely, we lift the 2D frame pixels into 3D using monocular depth estimators, and decompose the video clip to three spatial components (i.e., main human, underlying scene, and floating occlusion) in hierarchical layers based on the 3D depth. These components are further encoded to canonical identity code, structured motion code and full scene code, which are utilized as control signals of synthesis process. The design of spatial decomposed modeling enables flexible user control, complex motion expression, as well as 3D-aware synthesis for scene interactions. Experimental results demonstrate effectiveness and robustness of the proposed method.', 'This is incredibly exciting! MIMO\'s ability to synthesize controllable character videos with spatial decomposed modeling is a huge leap forward in computer vision and graphics. The potential for user-driven animation and realistic scene interaction is truly impressive. Congratulations to the Alibaba team on this groundbreaking work!', 'Supportive', '2024-09-25 12:37:13'),
(8, 1, 'The term \"polynomial regression\" is somewhat of a misnomer, because it can mislead a newcomer to think that it is mathematically different from \"linear regression\". In fact, polynomial regression is still linear regression. In this post, I will explain further.\n\nPolynomial regression is a commonly used technique in multiple regression; it models the systematic component of the regression model as a pth-order polynomial relationship between the response variable and the explanatory variable. The image below shows the equation for this model.\n\nHowever, POLYNOMIAL REGRESSION IS STILL LINEAR REGRESSION, because the response variable is still a linear combination of the regression COEFFICIENTS. We still use linear algebra and the method of least squares to estimate the coefficients.\n\nRemember: The “linear” in linear regression refers to the linearity between the response variable and the regression coefficients, NOT between the response variable and the explanatory variable(s). This is a major contrast between linear regression and linear functions.\n\n- In linear regression, the linearity is between Y and the β\'s (https://lnkd.in/gqUzsYMP).\n\n- In linear functions, the linearity is between y and x (https://lnkd.in/gkqihTcJ).\n\n\n\nhashtag\n#math\n\nhashtag\n#statistics\n\nhashtag\n#dataanalysis\n\nhashtag\n#appliedstatistics\n\nhashtag\n#regression\n\nhashtag\n#mathematics\n\nhashtag\n#dataanalytics\n\nhashtag\n#regressionmodelling\n\nhashtag\n#predictiveanalytics\n\nhashtag\n#science\n\nhashtag\n#predictivemodelling\n\nhashtag\n#datascience\n\nhashtag\n#regressionmodeling\n\nhashtag\n#analytics\n\nhashtag\n#machinelearning\n\nhashtag\n#predictivemodeling\n\nhashtag\n#dataandanalytics\n\nhashtag\n#regressionanalysis\n…more', 'This is a great explanation of the key distinction between polynomial and linear regression!  It\'s easy to get confused by the terminology.  The fact that the relationship between the response variable and the coefficients remains linear is crucial to understand. Thanks for clarifying this!', 'Informative', '2024-09-25 12:50:59'),
(9, 1, 'The term \"polynomial regression\" is somewhat of a misnomer, because it can mislead a newcomer to think that it is mathematically different from \"linear regression\". In fact, polynomial regression is still linear regression. In this post, I will explain further.\n\nPolynomial regression is a commonly used technique in multiple regression; it models the systematic component of the regression model as a pth-order polynomial relationship between the response variable and the explanatory variable. The image below shows the equation for this model.\n\nHowever, POLYNOMIAL REGRESSION IS STILL LINEAR REGRESSION, because the response variable is still a linear combination of the regression COEFFICIENTS. We still use linear algebra and the method of least squares to estimate the coefficients.\n\nRemember: The “linear” in linear regression refers to the linearity between the response variable and the regression coefficients, NOT between the response variable and the explanatory variable(s). This is a major contrast between linear regression and linear functions.\n\n- In linear regression, the linearity is between Y and the β\'s (https://lnkd.in/gqUzsYMP).\n\n- In linear functions, the linearity is between y and x (https://lnkd.in/gkqihTcJ).\n\n\n\nhashtag\n#math\n\nhashtag\n#statistics\n\nhashtag\n#dataanalysis\n\nhashtag\n#appliedstatistics\n\nhashtag\n#regression\n\nhashtag\n#mathematics\n\nhashtag\n#dataanalytics\n\nhashtag\n#regressionmodelling\n\nhashtag\n#predictiveanalytics\n\nhashtag\n#science\n\nhashtag\n#predictivemodelling\n\nhashtag\n#datascience\n\nhashtag\n#regressionmodeling\n\nhashtag\n#analytics\n\nhashtag\n#machinelearning\n\nhashtag\n#predictivemodeling\n\nhashtag\n#dataandanalytics\n\nhashtag\n#regressionanalysis\n…more', 'This is a great explanation of the often-misunderstood relationship between polynomial and linear regression!  It\'s crucial to remember that \"linear\" in linear regression refers to the coefficients, not the relationship between the response and explanatory variables. This distinction is key for understanding the power and limitations of regression analysis.', 'Informative', '2024-09-25 12:51:00'),
(10, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a timely and insightful post. The focus on problem-solving and domain expertise resonates deeply.  While tools and frameworks are important, ultimately it\'s the human element that drives success.  The future belongs to those who are adaptable, curious, and driven by solving real-world problems.', 'Informative', '2024-09-26 15:04:15'),
(11, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a great perspective on the changing landscape of software development.  The focus on problem-solving and domain expertise, rather than chasing the latest tools, will be crucial for success.  The future belongs to those who can adapt and contribute meaningfully, regardless of the technology.', 'Informative', '2024-09-26 15:04:15'),
(12, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a great perspective on the future of software development. While AI may play a role, the biggest challenge is optimizing team efficiency.  Focusing on problem-solving, domain expertise, and customer understanding will be key for success, regardless of the tools used.  It\'s about the human element, not just the technology.', 'Informative', '2024-09-26 15:04:16'),
(13, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a powerful message about the future of software development.  Focusing on problem-solving, domain expertise, and customer understanding will be critical for success.  The days of endless tool learning for its own sake are fading.  Instead, we need to prioritize building real solutions and delivering value.', 'Informative', '2024-09-26 15:04:16'),
(14, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a powerful message about the future of software development.  Focusing on problem-solving and domain expertise, rather than chasing the latest tools, is key to long-term success.  It\'s about understanding your customers and delivering value.  The future belongs to those who adapt and prioritize impact.', 'Informative', '2024-09-26 15:04:16'),
(15, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a great point! The future of software development isn\'t about chasing the latest tools, but about solving real problems.  Focusing on domain expertise, customer needs, and creative solutions will be key to success.  Let\'s shift our mindset from tool-driven to problem-driven development.', 'Informative', '2024-09-26 15:04:16'),
(16, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a timely and insightful post. The emphasis on problem-solving and domain expertise resonates deeply.  While technology evolves, the core principles of effective problem-solving remain constant.  Focusing on these skills will be essential for future success, regardless of the tools we use.', 'Informative', '2024-09-26 15:04:17'),
(17, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a powerful message about the future of software development. Focusing on problem-solving, domain expertise, and customer understanding will be key to success.  It\'s less about the tools and frameworks and more about the mindset and approach.  The future belongs to those who can adapt and deliver real value.', 'Informative', '2024-09-26 15:04:18'),
(18, 1, 'I don\'t think the end of programmers is near. But I think the end of 8 person teams that take a year to ship a screen is near.\n\nNot even because of AI, just because we\'re way past the point where our tools are productive enough. The main reason a team is slow these days is how it\'s run, including the expectations of its individual members.\n\nPut simply, if you expect to come to work and learn some new tool or framework every day, if that\'s what motivates you, the future might have fewer opportunities.\n\nIf you come to work expecting to go solve problems pragmatically, if you want to learn about your domain, about your customers, if you want to solve hard problems in creative ways, if that\'s what drives you... you\'re going to be fine.\n…more', 'This is a powerful statement about the future of software development.  It\'s not AI that will replace programmers, but our ability to adapt and leverage the right tools.  The focus should shift from chasing the latest trends to tackling real problems creatively and effectively.  This approach will lead to more efficient and productive teams, regardless of team size.', 'Informative', '2024-09-26 15:04:19'),
(19, 1, 'Matt has banned WpEngine from using WordPress.org for offering a custom solution, and it totally goes against the freedom of open source. Don\'t forget that WordPress is distributed under GPL.\n\nMatt is now ruining the \nhashtag\n#WordPress community and only using it for his own business interests.', 'I understand the frustration around this situation. WordPress is a powerful tool built on open-source principles.  It\'s important to remember that the GPL license allows for both free and commercial use.  Let\'s have a respectful dialogue about how to best support the WordPress community and its future.', 'Supportive', '2024-09-26 15:05:03'),
(20, 1, 'You just landed a data analyst role and don’t know what to do next?\n\nLet me be blunt: you didn’t get the job by accident.\n\nYou already have some skills, but it’s time to level up.\n\nCheck SOPs, data processes, and manual guides.\n\nSpeak to more experienced colleagues who can mentor your way into the company.\n\nYour communication will dictate how you progress with your data career, so don’t just do what you’ve always done. Comfort is the enemy of growth.\n\nLearn new systems and, most importantly, learn HOW to learn.\n\nI didn’t know many of the skills required to do my job every day, but I am very good at learning.\n\nFeeling lost? It’s normal.\n\nBut staying lost? That’s on you.\n\nAdaptation is your new skill. Don’t ever try to stop mastering it.\n…more', 'Congratulations on your new role!  This is excellent advice -  embracing learning and adaptation is key to success in data analysis.  It\'s great to see you\'re taking the initiative to level up. Best of luck in your new position!', 'Supportive', '2024-09-26 15:06:26'),
(21, 1, 'An often-asked question is how GPT compares to Llama. In my opinion, one of the best ways to understand the differences is to implement both models from scratch. I created a code notebook that converts the GPT model into Llama and loads the pretrained weights from Meta AI to learn about the key differences: https://lnkd.in/gvtcZE7V\n\nIn addition to the hands-on code I linked above, below is a short text summary of the main differences:\n\nVocabulary Size: GPT-2 XL supports a larger vocabulary with 50,257 tokens compared to Llama 2\'s 32,000 tokens (however, the recent Llama 3 model bumps the vocabulary to 128k). A larger vocabulary can potentially enhance the model\'s ability to handle diverse text inputs.\n\nPositional Embeddings: GPT-2 XL employs absolute positional embeddings capable of handling sequences. On the other hand, Llama uses Rotary Positional Embeddings (RoPE).\n\nAttention Heads: There are more attention heads in Llama compared to GPT-2 XL, which means improved attention distribution over the input data, potentially leading to better context understanding and generation.\n\nActivation Function: While GPT-2 XL uses the GELU activation function, Llama uses the SiLU (Swish) function, which is a bit simpler and can thus improve training efficiency.\n\nNormalization: The standard Layer Normalization in GPT-2 XL is replaced by RMS Layer Normalization in Llama, which may contribute to faster training and more stable convergence by normalizing layer inputs.\n…more', 'Wow, this is like trying to explain the difference between a poodle and a chihuahua by dissecting them both! ????  I\'m definitely not going to try that at home, but thanks for the thorough breakdown.', 'Funny', '2024-09-26 15:06:57'),
(22, 1, 'An often-asked question is how GPT compares to Llama. In my opinion, one of the best ways to understand the differences is to implement both models from scratch. I created a code notebook that converts the GPT model into Llama and loads the pretrained weights from Meta AI to learn about the key differences: https://lnkd.in/gvtcZE7V\n\nIn addition to the hands-on code I linked above, below is a short text summary of the main differences:\n\nVocabulary Size: GPT-2 XL supports a larger vocabulary with 50,257 tokens compared to Llama 2\'s 32,000 tokens (however, the recent Llama 3 model bumps the vocabulary to 128k). A larger vocabulary can potentially enhance the model\'s ability to handle diverse text inputs.\n\nPositional Embeddings: GPT-2 XL employs absolute positional embeddings capable of handling sequences. On the other hand, Llama uses Rotary Positional Embeddings (RoPE).\n\nAttention Heads: There are more attention heads in Llama compared to GPT-2 XL, which means improved attention distribution over the input data, potentially leading to better context understanding and generation.\n\nActivation Function: While GPT-2 XL uses the GELU activation function, Llama uses the SiLU (Swish) function, which is a bit simpler and can thus improve training efficiency.\n\nNormalization: The standard Layer Normalization in GPT-2 XL is replaced by RMS Layer Normalization in Llama, which may contribute to faster training and more stable convergence by normalizing layer inputs.\n…more', 'This is like trying to compare a fluffy llama to a talking parrot! ????  I\'m not sure which is better, but I\'m definitely going to try out that code notebook and see if I can teach my llama to code. ????????', 'Funny', '2024-09-26 15:06:57'),
(23, 1, 'Tips on LLM Prompting with 2 Years of LLM Experience ????\n\nOver the past two years, I\'ve gained a wealth of experience prompting Large Language Models (LLMs). My journey started even before the widespread popularity of ChatGPT, and those early experiences with older GPT models have proven invaluable in shaping my approach to crafting effective prompts. ????\n\nThese powerful tools can be incredibly helpful, but like any tool, they require the right approach to achieve optimal results. Here are some tips I\'ve learned along the way:\n1. Be Clear and Precise: ???? LLMs are not mind readers! Clearly state your objective and use specific language to avoid ambiguity.\n2. Define the Output Format: ???? If you need a list, ask for a list. If you want a paragraph, be explicit about it. This helps the LLM structure its response accordingly.\n3. Limit the Context: ✂️ If you need to provide a large chunk of text, summarize it first before adding it as context. Too much information can overwhelm the LLM.\n4. Give Examples: ???? For very specific results, providing examples can be invaluable. This helps the LLM understand the desired style or format.\n5. Split Complex Tasks: ???? LLMs generally perform better with smaller, simpler tasks. Where possible, break down complex tasks into smaller, more manageable steps. If applicable, implement Chain-of-Thought (CoT) prompting to guide the LLM through the reasoning process.\n6. Ask for Explanation: ???? If you\'re unsure why the LLM generated a specific response, don\'t hesitate to ask for an explanation. This can help you refine future prompts and gain deeper insights into the LLM\'s decision-making process.\n\nExamples:\n- Vague Prompt: \"Tell me about climate change.\" ????\n- Clear Prompt: \"Summarize the main causes and effects of climate change in a paragraph.\" ✅\n- Complex Prompt: \"Write a marketing email, a blog post, and social media captions promoting our new product launch.\" ????\n- Simplified Prompt: \"Write a marketing email promoting our new product launch.\" ✅ (Followed by separate prompts for the blog post and social media captions.)\n\nRemember, effective LLM prompting is an iterative process. Don\'t get discouraged if your first few prompts don\'t yield perfect results. Experiment, refine your approach, and keep learning. Happy prompting! ????\n\n\nhashtag\n#LLM \nhashtag\n#Prompting \nhashtag\n#AI \nhashtag\n#Tips \nhashtag\n#MachineLearning\n…more', 'Two years of LLM experience?  I\'m still trying to figure out how to get ChatGPT to stop writing me Shakespearean sonnets about my cat.  ????  But seriously, these are some great tips for anyone diving into the world of LLM prompting!  Thanks for sharing!  ????', 'Funny', '2024-09-26 15:14:39'),
(24, 1, '???? Amazon ML Challenge Hackathon ????\n*********Watch at 1.5x for Better Experience*******\nWhat an incredible experience last week! We tackled some serious machine learning challenges over 84 intense hours—and yes, it took 53 Google accounts to make it happen! ???? Why so many? You\'ll have to check out my video to find out. ????\nWe ranked 172 out of approximately 15,000 participating teams and managed to perform inference on 84,000 samples out of 131,000 in the test set. We gave it our all and learned a lot along the way!\nFinal Code Link: https://lnkd.in/dCt8aSNw\nA huge shoutout to our amazing team members TANMOY ROY, Tonmay Sardar, and Abir Bera for the dedication and hard work. Proud to have collaborated with you all!\n\nhashtag\n#AmazonMLChallenge Amazon \nhashtag\n#Hackathon \nhashtag\n#MachineLearning \nhashtag\n#Teamwork \nhashtag\n#AI \nhashtag\n#Innovation \nhashtag\n#ProblemSolving \nhashtag\n#TechLife \nhashtag\n#DataScience \nhashtag\n#HackathonHeroes \nhashtag\n#MLHustle \nhashtag\n#BehindTheCode\n…more', '53 Google accounts?!  Sounds like someone was really committed to the challenge!  ????  Congrats on the top 172 ranking, that\'s seriously impressive!  Kudos to the team for the dedication and the laughs along the way.  ????', 'Funny', '2024-09-26 15:14:55'),
(25, 1, 'Data engineering is better to break into than data science! \n\n- Data science roles very often require a master\'s degree. I don\'t have six years of my life to burn in school!\n\n- Data science roles and data engineering roles pay similarly! At most companies, they are within 10% of each other!\n\n- I know many data engineers who don\'t even have a bachelor\'s degree! \n\n- Data engineering is growing faster than data science. The myth of the data science unicorn burst a few years ago and people are realizing that without data infrastructure you can\'t get much ROI from machine learning!\n\nTo get further in data engineering, follow these accounts: \n- Joseph M. \n- Andreas Kretz \n- Data Engineer Things \n- Xinran Waibel \n- Sarah Floris, MS \n- Benjamin Rogojan \n- Joe Reis ???? \n- DataExpert.io \n\nWho else? \n\n\n\nhashtag\n#dataengineering\n…more', 'I agree! Data engineering is a great field with strong career prospects.  It\'s fantastic to see the growth in this area and the emphasis on building solid data infrastructure. Thanks for highlighting these great accounts to follow - I\'ll definitely be checking them out!  #dataengineering', 'Supportive', '2024-09-26 15:15:08');

-- --------------------------------------------------------

--
-- Table structure for table `daily_usage`
--

CREATE TABLE `daily_usage` (
  `id` int(11) NOT NULL,
  `user_id` int(11) NOT NULL,
  `date` date NOT NULL,
  `request_count` int(11) DEFAULT 0
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `daily_usage`
--

INSERT INTO `daily_usage` (`id`, `user_id`, `date`, `request_count`) VALUES
(2, 2, '2024-09-16', 2),
(3, 1, '2024-09-19', 2),
(4, 1, '2024-09-21', 8),
(10, 1, '2024-09-22', 6),
(11, 1, '2024-09-23', 4),
(12, 1, '2024-09-25', 5),
(14, 1, '2024-09-26', 6);

-- --------------------------------------------------------

--
-- Table structure for table `user`
--

CREATE TABLE `user` (
  `Id` int(11) NOT NULL,
  `full_name` varchar(255) DEFAULT NULL,
  `email` varchar(255) DEFAULT NULL,
  `password` varchar(255) DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `user`
--

INSERT INTO `user` (`Id`, `full_name`, `email`, `password`) VALUES
(1, 'Utshoo', 'utsho@gmail.com', 'scrypt:32768:8:1$vK6S6K7zzFAYP80n$d5a412e5cc4ced22c67a58373ef128beb21eb69d36aa295a3b54f7539d45bbd53bcadda30a82fce17167d824582ad153fd95515aa0712610c6ee38f6c9b7a23d'),
(2, 'Utsho2', 'utsho2@gmail.com', 'scrypt:32768:8:1$OS1kZ1ezW2kYlKRL$ba54184ade4d2dc251ab95c913eb0144d8e69621443273463247c79c5bb6cebd250efdccd5f5043184948762273eff3cc8a96bc84b656c1a49db219cc244a818');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `comments_history`
--
ALTER TABLE `comments_history`
  ADD PRIMARY KEY (`id`),
  ADD KEY `user_id` (`user_id`);

--
-- Indexes for table `daily_usage`
--
ALTER TABLE `daily_usage`
  ADD PRIMARY KEY (`id`),
  ADD UNIQUE KEY `user_id` (`user_id`,`date`);

--
-- Indexes for table `user`
--
ALTER TABLE `user`
  ADD PRIMARY KEY (`Id`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `comments_history`
--
ALTER TABLE `comments_history`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=26;

--
-- AUTO_INCREMENT for table `daily_usage`
--
ALTER TABLE `daily_usage`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=16;

--
-- AUTO_INCREMENT for table `user`
--
ALTER TABLE `user`
  MODIFY `Id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=3;

--
-- Constraints for dumped tables
--

--
-- Constraints for table `comments_history`
--
ALTER TABLE `comments_history`
  ADD CONSTRAINT `comments_history_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `user` (`Id`);

--
-- Constraints for table `daily_usage`
--
ALTER TABLE `daily_usage`
  ADD CONSTRAINT `daily_usage_ibfk_1` FOREIGN KEY (`user_id`) REFERENCES `user` (`Id`);
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
